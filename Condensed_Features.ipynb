{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering : Condensed Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import datetime\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangge/Documents/DB_proj/env/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_filepath = 'data/agg_train.csv'\n",
    "train_df = pd.read_table(train_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangge/Documents/DB_proj/env/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_filepath = 'data/test.csv'\n",
    "test_df = pd.read_table(test_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate date for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer string to date and time\n",
    "def date_trans(str_time):\n",
    "    if type(str_time) != str:\n",
    "        return datetime.datetime(2000, 1, 1)\n",
    "    format = \"%Y-%m-%d %H:%M:%S.0\"\n",
    "    return datetime.datetime.strptime(str_time,format)\n",
    "\n",
    "# create series of pandas date and time\n",
    "def trans_date_time_series(data):\n",
    "    cat = \"Step Start Time\"\n",
    "    str_chosen_time = list(data[cat])\n",
    "    date_time = [date_trans(x) for x in str_chosen_time]\n",
    "    date = [x.date() for x in date_time]\n",
    "    datetime_s = pd.to_datetime(date_time)\n",
    "    date_s = pd.to_datetime(date)\n",
    "    return (date_s,datetime_s)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to wash Knowledge Component\n",
    "def wash_KC(x):\n",
    "    if type(x) != str:\n",
    "        x = 'Null'\n",
    "    return x\n",
    "\n",
    "\n",
    "def split_unit(row):\n",
    "    return row[\"Problem Hierarchy\"].split(',')[0].strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find related Knowlegde Component in History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a dataframe for the relations of Sid, KC and Time\n",
    "def gen_history_df(data):\n",
    "    date,date_time = trans_date_time_series(data)\n",
    "\n",
    "    data['Date and Time'] = date_time\n",
    "    data['Date'] = date\n",
    "    return data.groupby(['Anon Student Id','KC(Default)','Date']).size()\n",
    "    \n",
    "\n",
    "\n",
    "def get_history_range(row,df,rg):\n",
    "    t = row[\"Row\"]\n",
    "    Sid = row[\"Anon Student Id\"]\n",
    "    KC = row[\"KC(Default)\"]\n",
    "    Date = row[\"Date\"].date()\n",
    "    td = pd.Timedelta(rg)\n",
    "    dates = []\n",
    "    while td >= pd.Timedelta(0):\n",
    "        dates.append(Date-td)\n",
    "        td -= pd.Timedelta('1 days')\n",
    "    try:\n",
    "        return df.loc[Sid].loc[KC].loc[dates].sum()\n",
    "    except KeyError:\n",
    "        return 0\n",
    "    \n",
    "# allocate temporal features to test data\n",
    "def find_temporal(row,train_df,kc_his):\n",
    "#     return 0\n",
    "    unit = row['Unit']\n",
    "    sid = row['Anon Student Id']\n",
    "    same_unit = train_df.loc[train_df['Unit']==unit].loc[train_df['Anon Student Id'] == sid]\n",
    "    print(type(same_unit))\n",
    "    if same_unit.shape[0] == 0:\n",
    "        return 0\n",
    "\n",
    "    res =  same_unit.iloc[-1][kc_his]\n",
    "    return res\n",
    "\n",
    "\n",
    "# Add temporal features to train    \n",
    "def train_temp(train):\n",
    "    #wash data\n",
    "    traindata['KC(Default)'] = traindata['KC(Default)'].apply(wash_KC)\n",
    "    #a table to look up to history kc\n",
    "    historytable = gen_history_df(train)\n",
    "    \n",
    "    today = \"0 days\"\n",
    "    train['KC History Today'] = train.apply(get_history_range,args=(historytable,today,),axis = 1)\n",
    "    \n",
    "    yestr = \"1 days\"\n",
    "    train['KC History Yesterday'] = train.apply(get_history_range,args=(historytable,yestr,),axis = 1)\\\n",
    "        - train['KC History Today']\n",
    "    week = \"7 days\"\n",
    "    train['KC History Week'] = train.apply(get_history_range,args=(historytable,week,),axis = 1) \\\n",
    "        - train['KC History Today']\n",
    "    \n",
    "    return train\n",
    "\n",
    "# Add temporal features to test data\n",
    "def test_temp(train,test):\n",
    "    test['KC(Default)'] = test['KC(Default)'].apply(wash_KC)\n",
    "    for kch_name in ['KC History Today','KC History Yesterday','KC History Week']:\n",
    "        print(kch_name)\n",
    "        test[kch_name] = test.apply(find_temporal,args=(train,kch_name),axis=1)\n",
    "\n",
    "    \n",
    "    return test\n",
    "    \n",
    "# main funcion to generate temporal features\n",
    "def temp_main(train,test):\n",
    "    train_df[\"Unit\"] = train_df.apply(split_unit,axis=1)\n",
    "    test_df['Unit'] = test_df.apply(split_unit,axis=1)\n",
    "    \n",
    "    train = train_temp(train)\n",
    "    test = test_temp(train,test)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct First Attempt Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_count_table(train,requested_list):\n",
    "    requested_list.append('Correct First Attempt')\n",
    "    cfa_cnt = train[requested_list].groupby(requested_list).size()\n",
    "    return cfa_cnt\n",
    "\n",
    "def cfa_for_test_2(row,table,request_2):\n",
    "    key1 = row[request_2[0]]\n",
    "    key2 = row[request_2[1]]\n",
    "    t = row[\"Row\"]\n",
    "    try:\n",
    "        c = table.loc[key1].loc[key2].loc[1]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "    try:\n",
    "        ic = table.loc[key1].loc[key2].loc[0]\n",
    "    except KeyError:\n",
    "        ic = 0 \n",
    "    return c / (c + ic)\n",
    "\n",
    "def cfa_for_train_2(row,table,request_2):\n",
    "    key1 = row[request_2[0]]\n",
    "    key2 = row[request_2[1]]\n",
    "    t = row[\"Row\"]\n",
    "#     print(t)\n",
    "    if 1 in table.loc[key1,key2].index:\n",
    "        c = table.loc[key1,key2,1]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    if 0 in table.loc[key1,key2].index:\n",
    "        ic = table.loc[key1,key2,0]\n",
    "    else:\n",
    "        ic = 0\n",
    "    return c / (c + ic)\n",
    "\n",
    "def cfa_for_test_1(row,table,request):\n",
    "    key1 = row[request[0]]\n",
    "    try:\n",
    "        c = table.loc[key1].loc[1]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "    try:\n",
    "        ic = table.loc[key1].loc[0]\n",
    "    except KeyError:\n",
    "        ic = 0 \n",
    "    return c / (c + ic)\n",
    "\n",
    "def cfa_for_train_1(row,table,request):\n",
    "    key1 = row[request[0]]\n",
    "#     print(key1)\n",
    "    t = row[\"Row\"]\n",
    "#     print(t)\n",
    "    if 1 in table.loc[key1].index:\n",
    "        c = table.loc[key1,1]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    if 0 in table.loc[key1].index:\n",
    "        ic = table.loc[key1,0]\n",
    "    else:\n",
    "        ic = 0\n",
    "    return c / (c + ic)\n",
    "\n",
    "\n",
    "def get_cfa_both(train,test,request):\n",
    "#     key should be a list\n",
    "\n",
    "    cfa_table = gen_count_table(train,request)\n",
    "#     print(cfa_table.index)\n",
    "    if len(request) == 2:\n",
    "        train_s = train.apply(cfa_for_train_1,args= (cfa_table,request),axis=1)\n",
    "        test_s = test.apply(cfa_for_test_1,args=(cfa_table,request),axis=1)\n",
    "    else:\n",
    "        train_s = train.apply(cfa_for_train_2,args= (cfa_table,request),axis=1)\n",
    "        test_s = test.apply(cfa_for_test_2,args=(cfa_table,request),axis=1)\n",
    "        \n",
    "    return train_s,test_s\n",
    "\n",
    "def get_cfa_test(train,test,request):\n",
    "    cfa_table = gen_count_table(train,request)\n",
    "#     print(cfa_table.index)\n",
    "    if len(request) == 2:\n",
    "        test_s = test.apply(cfa_for_test_1,args=(cfa_table,request),axis=1)\n",
    "    else:\n",
    "        test_s = test.apply(cfa_for_test_2,args=(cfa_table,request),axis=1)        \n",
    "    return test_s\n",
    "\n",
    "def main_cfa(train,test):\n",
    "    request_list = [[\"Anon Student Id\", \"Unit\"],[\"Anon Student Id\"],]\n",
    "    CFAR_features = [ nameOfCFAR(v) for v in request_list ]\n",
    "    for i in range(len(CFAR_features)):\n",
    "        col_name = CFAR_features[i]\n",
    "        train[col_name],test[col_name] = get_cfa_both(train,test,request_list[i])\n",
    "    return train,test\n",
    "\n",
    "def cfa_test(train,test):\n",
    "    request_list = [[\"Anon Student Id\", \"Unit\"],[\"Anon Student Id\"],]\n",
    "    CFAR_features = [ nameOfCFAR(v) for v in request_list ]\n",
    "    for i in range(len(CFAR_features)):\n",
    "        col_name = CFAR_features[i]\n",
    "        test[col_name] = get_cfa_test(train,test,request_list[i])\n",
    "    return test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ability Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the relation bewtween Correct answer and the number of hint\n",
    "def student_ability_KC_hint(row):\n",
    "    up = row[\"Corrects\"]\n",
    "    low = np.exp(row[\"Hints\"])\n",
    "    return up/low\n",
    "\n",
    "# the relation bewtween Correct answer and the KC's frequency\n",
    "def student_ability_KC_frequency(row):\n",
    "    up = row[\"Corrects\"]\n",
    "    oppo = row[\"Opportunity(Default)\"]\n",
    "    if type(oppo) != str:\n",
    "        oppo = 0\n",
    "    else:\n",
    "        oppo = oppo.split(\"~~\")\n",
    "        oppo = [int(x) for x in oppo]\n",
    "        oppo = min(oppo)    \n",
    "    return up / (oppo + int(row[\"KC History Today\"] + 1))\n",
    "\n",
    "\n",
    "def get_avg_KCF(row,table):\n",
    "    Sid = row[\"Anon Student Id\"]\n",
    "    KC = row[\"KC(Default)\"]\n",
    "    try:\n",
    "        return table.loc[Sid].loc[KC]['AVG_KCF']\n",
    "    except KeyError:\n",
    "        return 0\n",
    "        \n",
    "\n",
    "def get_avg_KCH(row,table):\n",
    "    Sid = row[\"Anon Student Id\"]\n",
    "    KC = row[\"KC(Default)\"]\n",
    "    try:\n",
    "        return table.loc[Sid].loc[KC]['AVG_KCH']\n",
    "    except KeyError:\n",
    "        return 0\n",
    "    \n",
    "def gen_ability_feature(data):\n",
    "    data[\"KC_F\"] = data.apply(student_ability_KC_frequency,axis = 1)\n",
    "    data[\"KC_H\"] = data.apply(student_ability_KC_hint,axis = 1)\n",
    "\n",
    "    sum_KCH_KCF = data.groupby([\"Anon Student Id\",\"KC(Default)\"])\n",
    "    sum_KCH_KCF = sum_KCH_KCF.aggregate(np.sum)\n",
    "    temp_count = sum_KCH_KCF[\"Corrects\"] + sum_KCH_KCF[\"Incorrects\"]\n",
    "    sum_KCH_KCF[\"count\"] = temp_count\n",
    "    sum_KCH_KCF[\"AVG_KCF\"] = sum_KCH_KCF[\"KC_F\"] / sum_KCH_KCF[\"count\"]\n",
    "    sum_KCH_KCF[\"AVG_KCH\"] = sum_KCH_KCF[\"KC_H\"] / sum_KCH_KCF[\"count\"]\n",
    "    sum_KCH_KCF = sum_KCH_KCF[[\"AVG_KCH\",\"AVG_KCF\"]]\n",
    "    \n",
    "    return sum_KCH_KCF\n",
    "\n",
    "def main_ability(train,test):\n",
    "    sum_KCH_KCF = gen_ability_feature(train)\n",
    "    train[\"ability from KC and Hints\"] = train.apply(get_avg_KCH,args=(sum_KCH_KCF,),axis = 1)\n",
    "    train[\"ability from KC and Frequency\"] = train.apply(get_avg_KCF,args=(sum_KCH_KCF,),axis = 1)\n",
    "    test[\"ability from KC and Hints\"] = test.apply(get_avg_KCH,args=(sum_KCH_KCF,),axis = 1)\n",
    "    test[\"ability from KC and Frequency\"] = test.apply(get_avg_KCF,args=(sum_KCH_KCF,),axis = 1)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pv_norm(row):\n",
    "    return row[\"Problem View\"] / (row[\"Problem View\"] + 1)\n",
    "\n",
    "def opp_norm(row):\n",
    "    col = \"Opportunity(Default)\"\n",
    "    v = np.asarray([int(s) if s.lower() != \"nan\" else 0 for s in str(row[col]).split(\"~~\")])\n",
    "    m = np.min(v)\n",
    "    return m / (m+1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize problem view and opportunity\n",
    "train_df[\"Problem View(Norm)\"] = train_df.apply(pv_norm, axis=\"columns\")\n",
    "train_df[\"Opportunity(Norm)\"] = train_df.apply(opp_norm, axis=\"columns\")\n",
    "\n",
    "test_df[\"Problem View(Norm)\"] = test_df.apply(pv_norm, axis=\"columns\")\n",
    "test_df[\"Opportunity(Norm)\"] = test_df.apply(opp_norm, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cfar\n",
    "train_df,test_df = main_cfa(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add historical data\n",
    "train_df,test_df = temp_main(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ability features\n",
    "trrain_df,test_df = main_ability(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "train_df.to_csv(\"data/agg_train.csv\",sep='\\t')\n",
    "test_df.to_csv(\"data/agg_test.csv\",sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
